{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCXLmpzN72-_"
      },
      "source": [
        "# **Install necessary packages and library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n81mxpC-jbCz"
      },
      "outputs": [],
      "source": [
        "# !pip install -q --upgrade ipython==7.9.0\n",
        "# !pip install -q --upgrade ipykernel==5.3.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOBqbNkzcDP2"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/datasets.git\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install torchaudio\n",
        "!pip install librosa\n",
        "!pip install jiwer\n",
        "!pip install datasets\n",
        "!pip install paramiko"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NdJjJz6LOem"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6dvS3m2cJ_E"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import GPUtil\n",
        "GPUtil.getAvailable()\n",
        "\n",
        "import torch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "if use_cuda:\n",
        "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
        "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
        "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
        "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  dev = \"cuda:2\"\n",
        "else:\n",
        "  dev = \"cpu\"\n",
        "device = torch.device(dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-9EkA061egR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXN9QhynR4Ro"
      },
      "source": [
        "# **unicode analyzer custom function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPgToZSSR2ix"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "\n",
        "# def removeTheUnicodeFromText(batch):\n",
        "#   chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\।\\\"u\\\\\\u[0-9A-Fa-f]+]'\n",
        "#   batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower() + \" \"\n",
        "\n",
        "#   return batch\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvzDwoJJ650o"
      },
      "source": [
        "# **Read data from server**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8dulQb77cW2"
      },
      "source": [
        "# **Read csv data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4nI_lHU7a8t"
      },
      "outputs": [],
      "source": [
        "# df= pd.read_csv('/content/drive/MyDrive/Bangla_STT/map_path_txt_phn.csv')\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er3cWR6J9XIl"
      },
      "outputs": [],
      "source": [
        "# df['speech'][0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq4bS8eNaAbn"
      },
      "source": [
        "# **Map wav file with text file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEMR5miedCmL"
      },
      "outputs": [],
      "source": [
        "import paramiko, re\n",
        "from tqdm import tqdm\n",
        "import sys, os, stat\n",
        "import torchaudio\n",
        "from paramiko import AutoAddPolicy\n",
        "import pandas as pd\n",
        "\n",
        "def get_file_paths(client, path, pattern):\n",
        "    stdin, stdout, stderr = client.exec_command(f\"find {path} -name *{pattern}  -type f -print0 | xargs -0 ls -t\")\n",
        "    output = stdout.read().decode().strip().split('\\n')\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "client = paramiko.SSHClient()\n",
        "client.load_system_host_keys()\n",
        "client.set_missing_host_key_policy(AutoAddPolicy())\n",
        "client.connect(hostname=\"SET YOUR HOST NAME\", username=\"SET YOUR USER NAME\", password=\"SET YOUR PASSWORD\")\n",
        "sftp_client = client.open_sftp()\n",
        "\n",
        "\n",
        "list_txts = []\n",
        "chunk_size = 10**3\n",
        "list_of_wavs = get_file_paths(client, \"PUT THE API URL\", \".wav\")[:20]\n",
        "\n",
        "for path in tqdm(list_of_wavs):\n",
        "    id = path.split('/')[-1].split('.')[0]\n",
        "    folder = path.split('/')[4]\n",
        "    text_path = f\"PUT THE BASE PATH/{folder}/PUT THE ADDITIONAL PATH{id}.txt\"\n",
        "    text_file = sftp_client.open(text_path)\n",
        "    #text_file = str(text_file)\n",
        "    text = \"\"\n",
        "    for line in text_file:\n",
        "        text = line\n",
        "    list_txts.append(text)\n",
        "    # print(text_path)\n",
        "\n",
        "\n",
        "df_new = pd.DataFrame(list(zip(list_of_wavs, list_txts)),\n",
        "               columns = ['audio_path', 'label'])\n",
        "\n",
        "df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DPYZhRCoooB"
      },
      "outputs": [],
      "source": [
        "df_new['label'] = df_new['label'].str.replace(r\"_1|_2\",\"\",regex = True)\n",
        "df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_bc88L3dfzu"
      },
      "outputs": [],
      "source": [
        "df_new['audio_path'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-lxZ0yoCLrV"
      },
      "outputs": [],
      "source": [
        "df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkFEACutp_VU"
      },
      "outputs": [],
      "source": [
        "len(df_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpYxBOzSoTIV"
      },
      "outputs": [],
      "source": [
        "train_data = df_new[:8]\n",
        "dev_data  = df_new[8:14]\n",
        "test_Data = df_new[14:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1P3DgKCpAdT"
      },
      "source": [
        "# **Base phoneme**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4d8eFG5pIDl"
      },
      "outputs": [],
      "source": [
        "vocab_dict =  {'a': 0, 'ã': 1, 'b': 2, 'bʰ': 3, 'c': 4, 'cʰ': 5, 'd': 6, 'dʰ': 7, 'd̪': 8, 'd̪ʰ': 9, 'e': 10, 'ẽ': 11, \n",
        "               'g': 12, 'gʰ': 13, 'h': 14, 'i': 15, 'ĩ': 16, 'i̯': 17, 'k': 18, 'kʰ': 19, 'l': 20, 'm': 21, 'n': 22, \n",
        "               'o': 23, 'õ': 24, 'o̯': 25, 'p': 26, 'pʰ': 27, 'r': 28, 's': 29, 't': 30, 'tʰ': 31, 't̪': 32, 't̪ʰ': 33, 'u': 34,\n",
        "               'ũ': 35, 'u̯': 36, 'æ': 37, 'æ̃': 38, 'ŋ': 39, 'ɔ': 40, 'ɔ̃': 41, 'ɟ': 42, 'ɟʰ': 43, 'ɽ': 44, 'ɽʰ': 45, 'ʃ': 46, \n",
        "               'ʲ': 47, 'ʷ': 48, ' ': 49}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ95giPmvAox"
      },
      "outputs": [],
      "source": [
        "print(len(vocab_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLg9ALL7q49l"
      },
      "outputs": [],
      "source": [
        "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
        "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
        "\n",
        "print(vocab_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aLrhI0ovGsR"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, load_metric\n",
        "\n",
        "train_data = Dataset.from_pandas(train_data)\n",
        "dev_data = Dataset.from_pandas(dev_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib-MaFYgwI-B"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X_qDnkKw7o4"
      },
      "outputs": [],
      "source": [
        "#/content/drive/MyDrive/Bangla_STT/base_phoneme.json\n",
        "\n",
        "\n",
        "import json\n",
        "with open('/home/elias/base_phoneme.json', 'w') as vocab_file:\n",
        "    json.dump(vocab_dict, vocab_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXBFwZ7Lr95z"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(vocab_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU8tfk9yrzjW"
      },
      "outputs": [],
      "source": [
        "print(len(vocab_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD-xyONmLOex"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2CTCTokenizer\n",
        "import pandas as pd\n",
        "tokenizer = Wav2Vec2CTCTokenizer(\"/home/elias/base_phoneme.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAICFMvpx6NP"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2FeatureExtractor\n",
        "\n",
        "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTmYSBaryIXw"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2Processor\n",
        "\n",
        "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ9W1OSvy8wx"
      },
      "outputs": [],
      "source": [
        "processor.save_pretrained(\"/content/drive/MyDrive/Bangla_STT/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvLse20KzGox"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QB2scwlszKTQ"
      },
      "outputs": [],
      "source": [
        "import torchaudio\n",
        "\n",
        "def speech_file_to_array_fn(batch):\n",
        "    sftp_client = client.open_sftp()\n",
        "    remote_file = sftp_client.open(batch[\"audio_path\"])\n",
        "\n",
        "    speech_array, sampling_rate = torchaudio.load( remote_file )\n",
        "    batch[\"speech\"] = speech_array[0].numpy()\n",
        "    batch[\"sampling_rate\"] = sampling_rate\n",
        "    batch[\"target_text\"] = batch[\"label\"]\n",
        "    return batch\n",
        "\n",
        "train_data = train_data.map(speech_file_to_array_fn, remove_columns = train_data.column_names)\n",
        "dev_data = dev_data.map(speech_file_to_array_fn, remove_columns=dev_data.column_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMSYJ-XZ4PS3"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def resample(batch):\n",
        "    batch[\"speech\"] = librosa.resample(np.asarray(batch[\"speech\"]), 48000, 16_000)\n",
        "    batch[\"sampling_rate\"] = 16_000\n",
        "    return batch\n",
        "\n",
        "train_data = train_data.map(resample, num_proc=4)\n",
        "dev_data = dev_data.map(resample, num_proc=4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqRNCZl04Whs"
      },
      "outputs": [],
      "source": [
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "rand_int = random.randint(0, len(train_data))\n",
        "\n",
        "ipd.Audio(data=np.asarray(train_data[rand_int][\"speech\"]), autoplay=True, rate=6000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPE8ftkv4kN1"
      },
      "outputs": [],
      "source": [
        "rand_int = random.randint(0, len(train_data)-1)\n",
        "\n",
        "print(\"Target text:\", train_data[rand_int][\"target_text\"])\n",
        "print(\"Input array shape:\", np.asarray(train_data[rand_int][\"speech\"]).shape)\n",
        "print(\"Sampling rate:\", train_data[rand_int][\"sampling_rate\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imZoePxq42ZR"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(batch):\n",
        "    # check that all files have the correct sampling rate\n",
        "    assert (\n",
        "        len(set(batch[\"sampling_rate\"])) == 1\n",
        "    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n",
        "\n",
        "    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]).input_values\n",
        "\n",
        "    with processor.as_target_processor():\n",
        "        batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n",
        "    return batch\n",
        "\n",
        "train_data = train_data.map(prepare_dataset, remove_columns=train_data.column_names, batch_size=32, num_proc=4, batched=True)\n",
        "dev_data = dev_data.map(prepare_dataset, remove_columns=dev_data.column_names, batch_size=32, num_proc=4, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur-EZ_ur5K0d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorCTCWithPadding:\n",
        "    \n",
        "\n",
        "    processor: Wav2Vec2Processor\n",
        "    padding: Union[bool, str] = True\n",
        "    max_length: Optional[int] = None\n",
        "    max_length_labels: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "    pad_to_multiple_of_labels: Optional[int] = None\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lenghts and need\n",
        "        # different padding methods\n",
        "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "\n",
        "        batch = self.processor.pad(\n",
        "            input_features,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        with self.processor.as_target_processor():\n",
        "            labels_batch = self.processor.pad(\n",
        "                label_features,\n",
        "                padding=self.padding,\n",
        "                max_length=self.max_length_labels,\n",
        "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U4BzjX85cel"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqiaouf65iU1"
      },
      "outputs": [],
      "source": [
        "wer_metric = load_metric(\"wer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7clEeFbx5o-2"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    pred_logits = pred.predictions\n",
        "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
        "\n",
        "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "    pred_str = processor.batch_decode(pred_ids)\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
        "\n",
        "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
        "    \n",
        "    mlflow.lod(\"wer\",wer)\n",
        "    return {\"wer\": wer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brk4zhwp5tn1"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2ForCTC\n",
        "\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\n",
        "    \"facebook/wav2vec2-large-xlsr-53\",\n",
        "    attention_dropout=0.1,\n",
        "    hidden_dropout=0.1,\n",
        "    feat_proj_dropout=0.0,\n",
        "    mask_time_prob=0.05,\n",
        "    layerdrop=0.1,\n",
        "    gradient_checkpointing=True,\n",
        "    ctc_loss_reduction=\"mean\",\n",
        "    ctc_zero_infinity=True,\n",
        "    pad_token_id=processor.tokenizer.pad_token_id,\n",
        "    vocab_size=len(processor.tokenizer)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aqfRzf9509t"
      },
      "outputs": [],
      "source": [
        "model.freeze_feature_extractor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6WxeE-_7Rgd"
      },
      "source": [
        "# **mlflow setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qqDO5BWd9LV"
      },
      "outputs": [],
      "source": [
        "pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaqIWln-94Zx"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "mlflow.set_experiment('LearnML-Demo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWAZklX87WZ2"
      },
      "outputs": [],
      "source": [
        "os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = \"0\"\n",
        "os.environ[\"MLFLOW_FLATTEN_PARAMS\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUVZlmeu5-Vs"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  hub_model_id = \"/home/eliasm/wav2vec2-mlflow\", \n",
        "  output_dir= \"/home/elias/\",\n",
        "\n",
        "  group_by_length=True,\n",
        "  per_device_train_batch_size=16,\n",
        "  per_device_eval_batch_size=16,\n",
        "  gradient_accumulation_steps=2,\n",
        "  evaluation_strategy=\"steps\",\n",
        "  num_train_epochs=30,\n",
        "  fp16=True,\n",
        "  save_steps=500,\n",
        "  eval_steps=500,\n",
        "  logging_steps=500,\n",
        "  learning_rate=4e-4,\n",
        "  warmup_steps=int(0.1*3600),\n",
        "  save_total_limit=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwsAV9Ai_ZMk"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=  model,\n",
        "    data_collator=  data_collator,\n",
        "    args=  training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=dev_data,\n",
        "    tokenizer=processor.feature_extractor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNjU_b7Bxbn4"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HN1eh0u_jv-"
      },
      "outputs": [],
      "source": [
        "#mlflow.end_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDkMw_Yn_lr9"
      },
      "outputs": [],
      "source": [
        "#trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-R6BqJkijun"
      },
      "outputs": [],
      "source": [
        "mlflow.set_tracking_uri(\"SET THE URL\") \n",
        "experiment_id = mlflow.get_experiment_by_name(\"wav2vec2\")\n",
        "if experiment_id is None:\n",
        "    experiment_id = mlflow.create_experiment(\"wav2vec2\")\n",
        "else:\n",
        "    experiment_id = experiment_id.experiment_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7wzp5-8adf3"
      },
      "outputs": [],
      "source": [
        "with mlflow.start_run(experiment_id= experiment_id):\n",
        "  trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmVXQDRPebeP"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI-UPL9_eP0F"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2cRHHD-fzJ1"
      },
      "outputs": [],
      "source": [
        "#!mlflow ui"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}